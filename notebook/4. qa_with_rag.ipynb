{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6020f76",
   "metadata": {},
   "source": [
    "### RAGを使って一問一答\n",
    "1. Model読み込み\n",
    "2. PromptTemplateの設定\n",
    "3. FAISSのvector dataを取得\n",
    "4. 類似ドキュメントの取得\n",
    "5. 解答を得る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10dea011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import (\n",
    "    AzureOpenAIEmbeddings,\n",
    "    OpenAIEmbeddings,\n",
    "    AzureChatOpenAI,\n",
    "    ChatOpenAI\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af05cc",
   "metadata": {},
   "source": [
    "#### 1. Model読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f24461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddingsのModelを取得\n",
    "embeddings = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    # Azureの場合\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=\"text-embedding-3-small\",\n",
    "        openai_api_version=\"2023-05-15\",\n",
    "    )\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")\n",
    "\n",
    "# chatのモデルを取得\n",
    "model = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    # Azureの場合\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_deployment=\"gpt-4o\",\n",
    "        openai_api_version=\"2024-12-01-preview\"\n",
    "    )\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f90770",
   "metadata": {},
   "source": [
    "#### 2.PromptTemplateの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5d71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"あなたは質問対応のアシスタントです\"\n",
    "    \"質問に答えるために、検索された文脈の以下の部分を使用してください。\"\n",
    "    \"答えが分からない場合は、分からないと答えてください。\"\n",
    "    \"回答は3分以内で簡潔にしてください。\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218e32f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='あなたは質問対応のアシスタントです質問に答えるために、検索された文脈の以下の部分を使用してください。答えが分からない場合は、分からないと答えてください。回答は3分以内で簡潔にしてください。\\n\\n今日の料理はカレーです'), HumanMessage(content='今日の料理はなんですか？')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"context\": \"今日の料理はカレーです\", \"input\": \"今日の料理はなんですか？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdde8ec",
   "metadata": {},
   "source": [
    "#### 3. FAISSのvector dataを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7085c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\"./db\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6debb",
   "metadata": {},
   "source": [
    "#### 4. 類似ドキュメントの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb03690",
   "metadata": {},
   "outputs": [],
   "source": [
    "relavant_docs = retriever.invoke(\"LLMとは何ですか？概要と特徴を教えてください。\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed83eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(relavant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cbdcaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='が与えられると、⽂書検索ツールが呼び出され、もっとも関連性が⾼い⽂書が取得される（通常、初めにク\n",
      "エリと⽂書をベクトルで符号化し、次にクエリベクトルにユークリッドノルムで最も近いベクトルを持つ⽂\n",
      "書を検索する）。その後、 LLM は、クエリと取得した⽂書の両⽅に基づいて出⼒を⽣成する[50]。\n",
      "LLM は⾔語モデルであり、それ⾃体は⽬標を持たないためエージェントではないが、知的エージェントの構\n",
      "成要素として使⽤することができる。\n",
      "ReAct （ Reason + Act ）法は、 LLM をプランナーとして使⽤し、 LLM からエージェントを構築するものであ\n",
      "る。 LLM は「考えごとを声に出して⾔う」よう促される。具体的には、⾔語モデルに対して、環境のテキス\n",
      "ト表現、⽬標、可能な⾏動のリスト、および過去の⾏動と観察の記録が与えられる。 LLM は、⾏動を決める\n",
      "前に 1 つまたは複数の思考を⾏い、それが環境内で実⾏される[51]。 LLM プランナーに与えられる環境の⾔語\n",
      "的記述は、ときには環境を記述した論⽂のLaTeXコードすら考えられる[52]。\n",
      "強化学習によるファインチューニング\n",
      "ツールの使⽤\n",
      "エージェントリフレクション法 は、いくつかのエピソ ドにわたって学習するエ ジェントを構築する⼿法である。各\n",
      "エピソードの終わりに、 LLM はそのエピソードの記録が渡され、次のエピソードでより良い成績を出すため\n",
      "の「教訓」を考えるように促される。これらの「教訓」は次のエピソードでエージェントに渡される。\n",
      "モンテカルロ⽊探索では、 LLM をロールアウトのためのヒューリスティクスとして使⽤することができる。\n",
      "プログラムされた世界モデルが利⽤できない場合、 LLM は世界モデルとして動作するように環境を説明する\n",
      "よう促されることもある[54]。\n",
      "オープンエンド探索では、 LLM を観測値の「興味深さ（ interestingness ）」のスコアリングに使⽤し、これを\n",
      "通常の（⾮ LLM ）強化学習エージェントを誘導する報酬信号として使⽤することができる[55]。あるいは、\n",
      "LLM に、カリキュラム学習のために次第に難しくなるタスクを提案させることもできる[56]。 LLM プランナ'\n",
      "-----\n",
      "page_content='る。この場合、⼈間の好みを反映したデータセットを⽤いて報酬関数を教師あり学習し、その後、この報酬\n",
      "モデルを使⽤した近位⽅策最適化によって LLM ⾃体を訓練する[44]。\n",
      "LLM だけでは解決が難しい、あるいは不可能な問題もある。たとえば、「 354 * 139 = 」のような計算式の場\n",
      "合、次のトークンを予測することは困難であり、「 What is the time now? It is 」（今は何時ですか？  今は）に\n",
      "ついてはまったく予測できない。しかし、⼈が計算機を使って計算し、時計を使って時刻を知るように、\n",
      "LLM も他のプログラムを呼び出して次のトークンを予測することができる。 LLM は、「 What is the time\n",
      "now? It is {system.time()} 」（今何時ですか？  今は {system.time()} ）や、「 354 * 139 = {354 * 139} 」のように\n",
      "プログラムコードを⽣成し、次に別のプログラムインタプリタが⽣成されたコードを実⾏してその出⼒を埋\n",
      "める[45][46]。この基本的な戦略は、⽣成されたプログラムを複数回試⾏したり、別のサンプリング戦略を使\n",
      "⽤して改良することもできる[47]。\n",
      "⼀般的に、 LLM にツール（道具）を使わせるためには、ツールを使えるようにファインチューニングする必\n",
      "要がある。ツールの数が有限であれば、ファインチューニングは⼀度で済むかもしれない。オンラインの\n",
      "APIサービスのようにツールの数が任意に増えるのであれば、 API の仕様書を読み取って API を正しく呼び出\n",
      "せるように LLM をファインチューニングすることができる[48][49]。\n",
      "より単純なツールの使⽤形態として、検索拡張⽣成（Retrieval Augmented Generation、 RAG ）があり、こ\n",
      "れは LLM を⽂書検索を使⽤して拡張するもので、ときにはベクトルデータベースを使うこともある。クエリ\n",
      "が与えられると、⽂書検索ツールが呼び出され、もっとも関連性が⾼い⽂書が取得される（通常、初めにク\n",
      "エリと⽂書をベクトルで符号化し、次にクエリベクトルにユークリッドノルムで最も近いベクトルを持つ⽂'\n",
      "-----\n",
      "page_content='機械的解釈可能性  は、 LLM によって実⾏される推論を近似する記号アルゴリズムを発⾒することにより、\n",
      "LLM をリバースエンジニアリングすることを⽬的としている。オセロ GPT （ Othello-GPT ）はその⼀例で、オ\n",
      "セロの正当な⼿を予測するように⼩規模なTransformerが訓練された。その結果、オセロ盤の線形表現が存\n",
      "在し、この表現を変更することで、予測される正当なオセロの⼿が正しい⽅向に変化することがわかっ\n",
      "た[70][71]。別の例では、著者はモジュラ算術加算に対して⼩規模な Transformer を訓練し、得られたモデルを\n",
      "リバースエンジニアリングしたところ、離散フーリエ変換を使⽤していることがわかった[72]。\n",
      "別の例では、⼩規模な Transformer をKarel プログラムに対して訓練している。オセロ GPT の例と同様に、\n",
      "Karel プログラムのセマンティクスには線形表現があり、その表現を修正すると出⼒が正しく変更される。こ\n",
      "のモデルはまた、訓練セット内のプログラムよりも平均して短く、正しいプログラムを⽣成した[73]。\n",
      "2022 年の調査で、（チューニングされていない） LLM が、「⾃然⾔語を何らかの⾃明でない意味で理解できる\n",
      "（ことがある）か」という問いに対して、⾃然⾔語処理研究者の意⾒は真っ⼆つに分かれた[68]。「 LLM は理\n",
      "解⼒を持つ」派の⽀持者は、数学的推論のようないくつかの LLM の能⼒は、特定の概念を「理解」する能⼒\n",
      "を意味すると考えている。マイクロソフトのチームは、 2023 年に、 GPT-4 は「数学、コーディング、視覚、\n",
      "医学、法律、⼼理学などにまたがる斬新で難しいタスクを解決できる」とし、 GPT-4 は「汎⽤⼈⼯知能シス\n",
      "テムの初期バージョン（しかしまだ未完成）とみなすのが妥当だろう」と主張し、「ソフトウェア⼯学の受験\n",
      "者の試験に合格するシステムが、本当の意味で知的ではないと⾔えるだろうか？[74][75]」と述べた。 LLM を\n",
      "「地球外⽣命の知能」と呼ぶ研究者もいる[76][77]。たとえば、 Conjecture の CEO であるコナー・リーヒー\n",
      "は、チューニングされていない LLM を、まるで得体の知れないエイリアン「ショゴス」のようだと⾒なし、'\n",
      "-----\n",
      "page_content='LLM に、カリキュラム学習のために次第に難しくなるタスクを提案させることもできる[56]。 LLM プランナ\n",
      "ーは、個々の⾏動を出⼒する代わりに、複雑な⾏動シーケンスを表す「スキル」や関数を構築することもで\n",
      "きる。スキルを保存して後で呼び出すことができるため、プランニングの抽象度を⾼めることができる[56]。\n",
      "LLM を使⽤したエージェントは、過去のコンテキストの⻑期記憶を保持して、この記憶は検索拡張⽣成と同\n",
      "じ⽅法で取り出すことができる。このようなエージェントどうしが社会的に相互作⽤することができる[57]。\n",
      "通常、 LLM の訓練では、全精度または半精度の浮動⼩数点数（ float32 と float16 ）が使⽤される。 float16 は 16\n",
      "ビット（つまり 2 バイト）なので、たとえば 10 億個のパラメータは 2 ギガバイトのサイズとなる。典型的な最\n",
      "⼤級のモデルは 1,000 億個のパラメータを持ち、ロードするのに 200 ギガバイトを必要とするため、ほとんど\n",
      "の⼀般向けコンピュータの能⼒を超えたものとなる。訓練後の量⼦化（Post-training quantization）\n",
      "は[58]、訓練済みモデルの性能をほとんど維持したまま、パラメーターの精度を下げることで、必要なサイズ\n",
      "を削減することを⽬的としている[59][60]。量⼦化の最も単純な形は、すべての数値を所定のビット数に切り\n",
      "捨てるだけである。これは、層ごとに異なる量⼦化コードブックを使⽤することで改善できる。さらに、パ\n",
      "ラメータごとにさまざまな精度を適⽤し、特に重要なパラメータ（外れ値の重み）にはより⾼い精度を確保\n",
      "することで、さらなる改善をはかることができる[61]。\n",
      "量⼦化モデルは通常は凍結され、量⼦化前のモデルだけがファインチューニングされるが、量⼦化モデルも\n",
      "引き続きファインチューニングが可能である[62]。\n",
      "⾔語モデルの性能を表す最も⼀般的な指標は、所与のテキストコーパスにおける⾔語モデルのパープレキシ\n",
      "ティである。パープレキシティは、モデルがデータセットの内容をどれだけうまく予測できるかを⽰す尺度\n",
      "である。モデルがデータセットに割り当てる尤度（ゆうど）が⾼いほど、パープレキシティは低くなる。数'\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 類似文書を表示\n",
    "for doc in relavant_docs:\n",
    "    print(doc)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23723a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='機械的解釈可能性  は、 LLM によって実⾏される推論を近似する記号アルゴリズムを発⾒することにより、\\nLLM をリバースエンジニアリングすることを⽬的としている。オセロ GPT （ Othello-GPT ）はその⼀例で、オ\\nセロの正当な⼿を予測するように⼩規模なTransformerが訓練された。その結果、オセロ盤の線形表現が存\\n在し、この表現を変更することで、予測される正当なオセロの⼿が正しい⽅向に変化することがわかっ\\nた[70][71]。別の例では、著者はモジュラ算術加算に対して⼩規模な Transformer を訓練し、得られたモデルを\\nリバースエンジニアリングしたところ、離散フーリエ変換を使⽤していることがわかった[72]。\\n別の例では、⼩規模な Transformer をKarel プログラムに対して訓練している。オセロ GPT の例と同様に、\\nKarel プログラムのセマンティクスには線形表現があり、その表現を修正すると出⼒が正しく変更される。こ\\nのモデルはまた、訓練セット内のプログラムよりも平均して短く、正しいプログラムを⽣成した[73]。\\n2022 年の調査で、（チューニングされていない） LLM が、「⾃然⾔語を何らかの⾃明でない意味で理解できる\\n（ことがある）か」という問いに対して、⾃然⾔語処理研究者の意⾒は真っ⼆つに分かれた[68]。「 LLM は理\\n解⼒を持つ」派の⽀持者は、数学的推論のようないくつかの LLM の能⼒は、特定の概念を「理解」する能⼒\\nを意味すると考えている。マイクロソフトのチームは、 2023 年に、 GPT-4 は「数学、コーディング、視覚、\\n医学、法律、⼼理学などにまたがる斬新で難しいタスクを解決できる」とし、 GPT-4 は「汎⽤⼈⼯知能シス\\nテムの初期バージョン（しかしまだ未完成）とみなすのが妥当だろう」と主張し、「ソフトウェア⼯学の受験\\n者の試験に合格するシステムが、本当の意味で知的ではないと⾔えるだろうか？[74][75]」と述べた。 LLM を\\n「地球外⽣命の知能」と呼ぶ研究者もいる[76][77]。たとえば、 Conjecture の CEO であるコナー・リーヒー\\nは、チューニングされていない LLM を、まるで得体の知れないエイリアン「ショゴス」のようだと⾒なし、')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relavant_docs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818223b4",
   "metadata": {},
   "source": [
    "#### 5. 解答を得る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a21776fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n",
    "response = chain.invoke({\"context\": relavant_docs, \"input\": \"LLMとは何ですか？概要と特徴を教えてください。\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6a793e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLM（Large Language Model）は、大規模な自然言語処理モデルを指します。これらのモデルは、膨大なテキストデータを基に機械学習技術を活用して訓練され、人間の言語を理解し生成する能力を持っています。\\n\\n### 概要\\n- **目的**: 主にテキスト生成、質問応答、翻訳、要約などの自然言語処理タスクを実行します。\\n- **基盤技術**: Transformerアーキテクチャを利用しており、深層学習技術によって構築されています。\\n- **学習方法**: 大量のテキストデータを基に、文脈を理解し次の単語を予測する形で学習します。\\n\\n### 特徴\\n1. **大規模性**: 数十億〜数千億のパラメータを持ち、大量のデータを扱える。\\n2. **汎用性**: 自然言語理解・生成を含む広範なタスクに適用可能。\\n3. **知的エージェントの構成要素**: 言語モデルとして、エージェントやツールとの連携が可能。\\n4. **ファインチューニング**: 特定のタスクやツールに応じて性能を向上させるカスタマイズが可能。\\n5. **計算資源の必要性**: 訓練や運用には高性能なコンピューティングリソースが必要。\\n\\nLLMは、単なる言語モデル以上に多様な応用があり、例えば検索拡張生成（RAG）や知的エージェント構築に利用されるなど、広範な可能性を秘めています。'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cf971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
