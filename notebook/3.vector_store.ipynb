{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5add11",
   "metadata": {},
   "source": [
    "### ベクトルストアでの利用\n",
    "1. FAISSに格納\n",
    "2. FAISSから取得\n",
    "3. FAISSでベクトル検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2e6a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from pypdf import PdfReader\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6dc706",
   "metadata": {},
   "source": [
    "#### 1. FAISSに格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cafbb54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⼤規模⾔語モデル\n",
      "出典 : フリー百科事典『ウィキペディア（ Wikipedia ）』\n",
      "⼤規模⾔語モデル（だいきぼげんごモデル、英: large language model、LLM）は、多数のパラメ\n"
     ]
    }
   ],
   "source": [
    "# 1.PDFファイルの読み込み\n",
    "pdf_page = PdfReader('./data/llm.pdf')\n",
    "text = ''\n",
    "# PDFデータをテキストに変換\n",
    "for page in pdf_page.pages:\n",
    "    text += page.extract_text()\n",
    "print(text[:100])  # 最初の100文字を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927c36ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docサイズ 64\n",
      "型 <class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "# 2. データをチャンクに小分けにする\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # チャンクの最大文字数\n",
    "    chunk_overlap=100, # チャンク間の重複文字数\n",
    ")\n",
    "docs = text_splitter.split_text(text) # テキストをチャンクに分割\n",
    "docs_chunks = text_splitter.create_documents(docs) # チャンクをドキュメントに変換\n",
    "print(\"Docサイズ\",len(docs_chunks))  # チャンクの数を表示\n",
    "print(\"型\",type(docs_chunks[0]))  # チャンクの型を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4cc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. OpenAIのEmbeddingModel取得\n",
    "embeddings = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=\"text-embedding-3-small\",\n",
    "        openai_api_version=\"2023-05-15\",\n",
    "    )\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434b1a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "docments 抽出: 100%|██████████| 64/64 [00:14<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# 4. ベクトル化\n",
    "# 一括でベクトル化する場合\n",
    "# faiss_db = FAISS.from_documents(documents=docs, embedding=embedings)\n",
    "\n",
    "# プログレスバーを表示しながらベクトル化\n",
    "faiss_db = None\n",
    "with tqdm(total=len(docs_chunks), desc=\"docments 抽出\") as pbar:\n",
    "    for d in docs_chunks:\n",
    "        if faiss_db:\n",
    "            faiss_db.add_documents([d])\n",
    "        else:\n",
    "            faiss_db = FAISS.from_documents([d], embeddings)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36df743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ベクトルストアの保存\n",
    "faiss_db.save_local(\"./db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9761966",
   "metadata": {},
   "source": [
    "#### 2. FAISSから取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44de2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル化データを読み込み\n",
    "vectorstore = FAISS.load_local(\"./db\", # ベクトル化データの保存先\n",
    "embeddings, # ベクトル化モデル\n",
    "allow_dangerous_deserialization=True # 危険なデシリアライズを許可\n",
    ")\n",
    "\n",
    "# retrieverを取得\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2498f1",
   "metadata": {},
   "source": [
    "#### 3. FAISSでベクトル検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a48cdb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='である。たとえば、 LLM は「 Can you teach an old dog new tricks? （年⽼いた⽝に新しい芸を教えられます\n",
      "か？）」という質問に対して、「you can't teach an old dog new tricks（⽼⽝に新しい芸を仕込むことはでき\n",
      "ない）」という英語の語法に触れた結果、⽂字通り真実でないにもかかわらず、「 No 」と答えるかもしれな\n",
      "い[67]。\n",
      "さらに、 AI が多肢選択式テスト（○ × 式テスト）において、必ずしも実際に訪ねられている設問を理解するこ\n",
      "となく表⾯的な問題⽂の統計的相関を利⽤して正解を推測し、「カンニング」する「ショートカット学習」と\n",
      "呼ばれるケースもある[68]。\n",
      "敵対的評価データセットのもう⼀つの例は、 Swag とその後継の HellaSwag である。これは、⽂章を完成させ\n",
      "るためにいくつかの選択肢から⼀つを選択しなければならない問題を集めたものである。不正解の選択肢\n",
      "は、⾔語モデルからサンプリングし、⼀連の分類器でフィルタリングすることで作成された。その結果、⼈\n",
      "タスク固有のデータセットとベンチマーク\n",
      "逆説的に構成された評価間にとっては些細な問題でも、デ タセットが作成された当時は、最先端の⾔語モデルの精度は思わしくな\n",
      "かった。たとえば、次のようなものである。\n",
      "フィットネスセンターの看板が⾒える。そして、エクササイズボールに座ったり横たわりなが\n",
      "ら、カメラに向かって話しかける男性が⾒える。その男性は、 ...\n",
      "a) ボールの上を⾛ったり降りたりして、運動の効果を効率的にする⽅法を実演している。\n",
      "b) すべての腕と脚を動かしてたくさんの筋⾁をつけている。\n",
      "c) 次にボールを投げ、グラフィックや⽣け垣の刈り込みの実演を⾒る。\n",
      "d) ボールの上で腹筋運動をしながら話をしている[69]。\n",
      "BERT は最も可能性の⾼い補完として b) を選択したが、正解は d) である[69]。\n",
      "⼤規模⾔語モデルは、それ⾃体が「ブラックボックス」であり、どのようにして⾔語タスクを実⾏できるの\n",
      "かは明らかではない。しかし、 LLM がどのように機能するかを理解するためのいくつかの⽅法がある。\n",
      "機械的解釈可能性  は、 LLM によって実⾏される推論を近似する記号アルゴリズムを発⾒することにより、'\n",
      "-----\n",
      "page_content='Language Assistant as a Laboratory for\n",
      "Alignment\". arXiv:2112.00861 (https://arxiv.\n",
      "org/abs/2112.00861) [cs.CL (https://arxiv.o\n",
      "rg/archive/cs.CL)]。\n",
      " 06. ^ Bai, Yuntao; Kadavath, Saurav; Kundu,\n",
      "Sandipan; et al. (15 December 2022).\n",
      "\"Constitutional AI: Harmlessness from AI\n",
      "Feedback\". arXiv:2212.08073 (https://arxiv.o\n",
      "rg/abs/2212.08073) [cs.CL (https://arxiv.or\n",
      "g/archive/cs.CL)]。\n",
      " 07. ^ “Language modelling at scale: Gopher,\n",
      "ethical considerations, and retrieval (https://\n",
      "www.deepmind.com/blog/language-modellin\n",
      "g-at-scale-gopher-ethical-considerations-and\n",
      "-retrieval)” (英語). www.deepmind.com. 2023\n",
      "年3⽉20⽇閲覧。\n",
      " 08. ^ a b c Hoﬀmann, Jordan; Borgeaud,\n",
      "Sebastian; Mensch, Arthur; et al. (29 March\n",
      "2022). \"Training Compute-Optimal Large\n",
      "Language Models\". arXiv:2203.15556 (http\n",
      "s://arxiv.org/abs/2203.15556) [cs.CL (http\n",
      "s://arxiv.org/archive/cs.CL)]。\n",
      " 09. ^ a b “LaMDA: Towards Safe, Grounded, and\n",
      "High-Quality Dialog Models for Everything (h\n",
      "ttps://ai.googleblog.com/2022/01/lamda-to'\n",
      "-----\n",
      "page_content='14. ^ a b Kaplan, Jared; McCandlish, Sam;\n",
      "Henighan, Tom; Brown, Tom B.; Chess,\n",
      "Benjamin; Child, Rewon; Gray, Scott;\n",
      "Radford, Alec et al. (2020). “Scaling Laws for\n",
      "Neural Language Models”. CoRR\n",
      "abs/2001.08361. arXiv:2001.08361.\n",
      "15. ^ Caballero, Ethan; Gupta, Kshitij; Rish, Irina;\n",
      "Krueger, David (2022). Broken Neural\n",
      "Scaling Laws. International Conference on\n",
      "Learning Representations (ICLR), 2023.\n",
      "16. ^ Ornes, Stephen (2023年3⽉16⽇). “The\n",
      "Unpredictable Abilities Emerging From Large\n",
      "AI Models (https://www.quantamagazine.or\n",
      "g/the-unpredictable-abilities-emerging-from-l\n",
      "arge-ai-models-20230316/)”. Quanta\n",
      "Magazine. 2023年5⽉13⽇閲覧。\n",
      "17. ^ Schaeﬀer, Rylan; Miranda, Brando; Koyejo,\n",
      "Sanmi (1 April 2023). \"Are Emergent\n",
      "Abilities of Large Language Models a\n",
      "Mirage?\". arXiv:2304.15004 (https://arxiv.or\n",
      "g/abs/2304.15004) [cs.AI (https://arxiv.org/\n",
      "archive/cs.AI)]。\n",
      "18. ^ Elman, Jeﬀrey L. (March 1990). “Finding\n",
      "Structure in Time” (http://doi.wiley.com/10.1\n",
      "207/s15516709cog1402_1) (英語).'\n",
      "-----\n",
      "page_content='は、チューニングされていない LLM を、まるで得体の知れないエイリアン「ショゴス」のようだと⾒なし、\n",
      "RLHF チューニングが LLM の内部構造を覆い隠す「⾒せかけの笑顔」を作り出すと考えている。『あまり無理\n",
      "をしなければ、笑顔のままだ。しかし（予期せぬ）プロンプトを与えると突然、狂気、奇妙な思考過程、そ\n",
      "して明らかに⼈間ではない理解といった巨⼤な裏の顔を覗かせる』[78][79]。\n",
      "対照的に、「 LLM は理解⼒を⽋く」派の⽀持者の中には、既存の LLM は「既存の⽂章を単に練り直し、組み\n",
      "替えているだけ」であると考えたり[77]、既存の LLM が予測能⼒、推論能⼒、主体性、説明可能性において\n",
      "依然として⽋点を抱えていることを指摘したりする⼈もいる[68]。たとえば、 GPT-4 は計画やリアルタイム学\n",
      "習においてもっともな⽋陥がある[75]。⽣成的LLM は、訓練データでは正当化されないような事実を⾃信を\n",
      "もって主張することが観察されており、この現象は「ハルシネーション（幻覚）」として知られている[80]。\n",
      "解釈\n",
      "理解⼒と知性神経科学者のテレンス セジュノウスキ （Terrence Sejnowski）は、 LLM の知性に関する専⾨家の意⾒の\n",
      "相違は、⾃然の叡智に基づく私たちの古い考え⽅が⼗分ではないことを⽰唆している」と主張してい\n",
      "る[68]。\n",
      "2023 年、科学雑誌  Nature Biomedical Engineering は、⼈間が書いたテキストと⼤規模⾔語モデルによって\n",
      "作成されたテキストを「正確に区別することはもはや不可能」であり、「汎⽤⼤規模⾔語モデルが急速に普\n",
      "及することはほぼ確実である。いずれは多くの業界を変えてゆくだろう。」と結論づけた[81]。ゴールドマ\n",
      "ン・サックスは 2023 年、⾔語⽣成 AI は今後 10 年間で世界の GDP を 7 % 増加させ、全世界で 3 億⼈の雇⽤を⾃\n",
      "動化にさらす可能性があると⽰唆した[82][83]。⼀部の投稿者は、偶発的または意図的な誤情報の作成や、そ\n",
      "の他の悪⽤に対して懸念を表明した[84]。たとえば、⼤規模⾔語モデルが利⽤できるようになると、バイオ\n",
      "より広範囲な影響テロを起こすのに必要な技術レ ルを下げる可能性がある。 イオセキュリティの研究者であるケビン エ'\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 類似文書の取得\n",
    "similar_docs = retriever.get_relevant_documents(\"言語分析\", k=3)\n",
    "# similar_docs = retriever.invole(\"言語モデル\", k=3)\n",
    "\n",
    "# 類似文書を表示\n",
    "for doc in similar_docs:\n",
    "    print(doc)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8990df26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
