{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13d1a8c",
   "metadata": {},
   "source": [
    "### RAGを使ってチャット\n",
    "1. Model読み込み\n",
    "2. PromptTemplateの設定\n",
    "3. FAISSのvector dataを取得\n",
    "4. Chatの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4a10fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import (\n",
    "    AzureOpenAIEmbeddings,\n",
    "    OpenAIEmbeddings,\n",
    "    AzureChatOpenAI,\n",
    "    ChatOpenAI\n",
    ")\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, \n",
    "    AIMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316530e",
   "metadata": {},
   "source": [
    "#### 1. Model読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca299b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddingのModelを取得\n",
    "\n",
    "mbeddings = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    # Azureの場合\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=\"text-embedding-3-small\",\n",
    "        openai_api_version=\"2023-05-15\",\n",
    "    )\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")\n",
    "\n",
    "# chatのモデルを取得\n",
    "model = None\n",
    "if os.getenv('AZURE_OPENAI_API_KEY') != \"\":\n",
    "    # Azureの場合\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_deployment=\"gpt-4o\",\n",
    "        openai_api_version=\"2024-12-01-preview\"\n",
    "    )\n",
    "else:\n",
    "    print(\"APIKeyの設定を確認してください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdcb3e2",
   "metadata": {},
   "source": [
    "#### 2.PromptTemplateの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dfaa91",
   "metadata": {},
   "source": [
    "##### 2-1. コンテキストから回答するプロンプトとChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777c1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"あなたは質問対応のアシスタントです。\"\n",
    "    \"質問に答えるために、検索された文脈の以下の部分を使用してください。\"\n",
    "    \"答えがわからない場合は、わからないと答えてください。\"\n",
    "    \"回答は3文以内で簡潔にしてください。\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7776a41",
   "metadata": {},
   "source": [
    "##### 2-2. 質問を要約するプロンプトとChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70772032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"あなたは、AIでチャットの質問を作り直すように求められています\"\n",
    "    \"チャット履歴と最新のユーザーメッセージがあり、そのメッセージは\"\n",
    "    \"チャット履歴のコンテキストを参照している質問である可能性があります\"\n",
    "    \"チャットの履歴が無くても、理解できる独立した質問を作成してください\"\n",
    "    \"絶対に質問に答えないでください\"\n",
    "    \"質問は、「教えてください。」「どういうことですか?」などAIに投げかける質問にしてください\"\n",
    "    \"メッセージが質問であれば、作り直してください。\"\n",
    "    \"「ありがとう」などメッセージが質問出ない場合は、メッセージを作り直さずに戻してください\"\n",
    "    \"\\n\\n\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "contextualize_chain = contextualize_q_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a204bdc",
   "metadata": {},
   "source": [
    "#### 3. FAISSのvector dataを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f3cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\"./db\", embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef354343",
   "metadata": {},
   "source": [
    "#### 4. Chatの実装\n",
    "チャットの実装では下記図のように2段階の処理をしていきます  \n",
    "<img src=\"./../docs/asset/image3.png\" width=\"600px\">  \n",
    "\n",
    "<a href=\"https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/\" target=_blank>Langchain Doc</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f8a1f",
   "metadata": {},
   "source": [
    "##### 4-1. 二つの質問をしてみる\n",
    " まず、1つ目のステップを確認していきます。  \n",
    " なぜ1つ目の処理をする必要があるのかをみるために、2つの質問をします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3afb64d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLMの訓練方法には主に2つの形式があります：自己回帰モデル（次単語予測）とマスク済みモデル（穴埋め）。さらに、次文予測などの補助タスクを使用してデータ分布の理解をテストすることもあります。通常、負対数尤度や交差エントロピー損失を最小化するように訓練されます。', response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 3145, 'total_tokens': 3246, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'detected': False, 'filtered': False}, 'protected_material_text': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-8114b2d9-75f3-4e4d-a5bc-398f541a641a-0', usage_metadata={'input_tokens': 3145, 'output_tokens': 101, 'total_tokens': 3246})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "msg1 = \"LLMはどんな訓練方法がありますか\"\n",
    "relavant_docs = retriever.invoke(msg1, k=3)\n",
    "chain.invoke({\"chat_history\": messages, \"context\": relavant_docs, \"input\": msg1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24fbc127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='教師ありファインチューニングは、事前訓練された言語モデルを特定のタスク（例: 感情分析や品詞タグ付け）に適応させるため、タスク固有のデータで追加訓練を行う方法です。モデルの既存の重みを保持しつつ、新しい重みを導入して訓練を行う場合が一般的です。これは、転移学習の一種として位置づけられます。', response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 2917, 'total_tokens': 3035, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2688}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'detected': False, 'filtered': False}, 'protected_material_text': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-43846293-3773-40a4-89e9-66b13bc307d6-0', usage_metadata={'input_tokens': 2917, 'output_tokens': 118, 'total_tokens': 3035})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"LLMはどんな訓練方法がありますか？\"),\n",
    "    AIMessage(content=\"LLMの訓練方法には、教師ありファインチューニング、強化学習、ツールのファインチューニング、検索拡張生成（RAG）などがあります\"),\n",
    "]\n",
    "msg2 = \"1つ目について教えてください。\"\n",
    "relavant_docs = retriever.invoke(msg2, k=3)\n",
    "chain.invoke({\"chat_history\": messages, \"context\": relavant_docs, \"input\": msg2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462cbf97",
   "metadata": {},
   "source": [
    "「\"1つ目について教えてください。\"」からだと正確なドキュメントが取得できない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "851037f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='り、場合によっては、類似の問題とその解決策のいくつかのテキスト例とともに提⽰する「プロンプティン\n",
      "グ技術」を使⽤して、追加の訓練なしでタスクを解決できることがわかった[2]。\n",
      "詳細は「ファインチューニング  ( 機械学習 )」を参照\n",
      "ファインチューニング（英: fine-tuning、微調整）とは、事前訓練された既存の⾔語モデルを、特定のタスク\n",
      "（例 : 感情分析、固有表現識別、品詞タグ付け）で（教師ありの）訓練を⾏うことによって修正する⼿法で\n",
      "ある。これは転移学習の⼀種である。⼀般的には、⾔語モデルの最終層と下流タスク（英: downstream\n",
      "tasks）の出⼒とを接続する新しい重みのセットを導⼊することになる。⾔語モデルの元の重みは「凍結」し\n",
      "たまま、それらを出⼒に接続する新しい重み層のみが訓練中に調節されるように構成する。また、元の重み\n",
      "をわずかずつ更新させたり、あるいは以前の凍結された層と⼀緒に更新されることもある[35]。\n",
      "「プロンプトエンジニアリング」および「少数ショット学習」も参照\n",
      "GPT-3 によって普及したプロンプトパラダイムでは[4]、解決すべき問題はテキストプロンプト（回答を促す\n",
      "指⽰）で定式化され、モデルは（推論して）補完を⽣成することによってそれを解決しなければならない。\n",
      "「少数ショットプロンプト」（英: few-shot prompting）の場合、プロンプトには類似した組（問題、解決）\n",
      "の少数の例が含まれる[2]。たとえば、映画レビューに対する感情をラベル付けする感情分析タスクは、次の\n",
      "ような例で回答が促される[4]。\n",
      "レビュー: この映画は気が沈む。\n",
      "感情: ネガティブ\n",
      "レビュー: この映画は素晴らしい!\n",
      "感情: \n",
      "もしモデルが「ポジティブ」と出⼒すれば、正しくタスクが解決されたことになる[37][41]。⼀⽅、「ゼロショ\n",
      "ットプロンプト」（英: zero-shot prompting）の場合、解決例を提供しない。同じ感情分析タスクに対するゼ\n",
      "ロショットプロンプトの例は、『映画レビューに関連するセンチメントは「この映画は素晴らしい ! 」』であ\n",
      "る[42]。\n",
      "LLM における少数ショットの性能は、 NLP タスクで競争⼒のある結果を達成することが⽰されており、とき'\n",
      "----\n",
      "page_content='である。たとえば、 LLM は「 Can you teach an old dog new tricks? （年⽼いた⽝に新しい芸を教えられます\n",
      "か？）」という質問に対して、「you can't teach an old dog new tricks（⽼⽝に新しい芸を仕込むことはでき\n",
      "ない）」という英語の語法に触れた結果、⽂字通り真実でないにもかかわらず、「 No 」と答えるかもしれな\n",
      "い[67]。\n",
      "さらに、 AI が多肢選択式テスト（○ × 式テスト）において、必ずしも実際に訪ねられている設問を理解するこ\n",
      "となく表⾯的な問題⽂の統計的相関を利⽤して正解を推測し、「カンニング」する「ショートカット学習」と\n",
      "呼ばれるケースもある[68]。\n",
      "敵対的評価データセットのもう⼀つの例は、 Swag とその後継の HellaSwag である。これは、⽂章を完成させ\n",
      "るためにいくつかの選択肢から⼀つを選択しなければならない問題を集めたものである。不正解の選択肢\n",
      "は、⾔語モデルからサンプリングし、⼀連の分類器でフィルタリングすることで作成された。その結果、⼈\n",
      "タスク固有のデータセットとベンチマーク\n",
      "逆説的に構成された評価間にとっては些細な問題でも、デ タセットが作成された当時は、最先端の⾔語モデルの精度は思わしくな\n",
      "かった。たとえば、次のようなものである。\n",
      "フィットネスセンターの看板が⾒える。そして、エクササイズボールに座ったり横たわりなが\n",
      "ら、カメラに向かって話しかける男性が⾒える。その男性は、 ...\n",
      "a) ボールの上を⾛ったり降りたりして、運動の効果を効率的にする⽅法を実演している。\n",
      "b) すべての腕と脚を動かしてたくさんの筋⾁をつけている。\n",
      "c) 次にボールを投げ、グラフィックや⽣け垣の刈り込みの実演を⾒る。\n",
      "d) ボールの上で腹筋運動をしながら話をしている[69]。\n",
      "BERT は最も可能性の⾼い補完として b) を選択したが、正解は d) である[69]。\n",
      "⼤規模⾔語モデルは、それ⾃体が「ブラックボックス」であり、どのようにして⾔語タスクを実⾏できるの\n",
      "かは明らかではない。しかし、 LLM がどのように機能するかを理解するためのいくつかの⽅法がある。\n",
      "機械的解釈可能性  は、 LLM によって実⾏される推論を近似する記号アルゴリズムを発⾒することにより、'\n",
      "----\n",
      "page_content='Generalized Autoregressive Pretraining for\n",
      "Language Understanding” (https://arxiv.org/\n",
      "abs/1906.08237). arXiv:1906.08237 [cs]\n",
      "2023年5⽉5⽇閲覧。.\n",
      "92. ^ “GPT-2: 1.5B Release (https://web.archive.\n",
      "org/web/20191114074358/https://openai.c\n",
      "om/blog/gpt-2-1-5b-release/)” (英語).\n",
      "OpenAI (2019年11⽉5⽇). 2019年11⽉14⽇時\n",
      "点のオリジナル (https://openai.com/blog/gpt-\n",
      "2-1-5b-release/)よりアーカイブ。2019年11⽉\n",
      "14⽇閲覧。\n",
      "93. ^ “Better language models and their\n",
      "implications (https://openai.com/research/b\n",
      "etter-language-models)”. openai.com. 2023年\n",
      "4⽉28⽇閲覧。\n",
      "94. ^ a b “OpenAI's GPT-3 Language Model: A\n",
      "Technical Overview (https://lambdalabs.co\n",
      "m/blog/demystifying-gpt-3)” (英語).\n",
      "lambdalabs.com. 2023年4⽉28⽇閲覧。\n",
      "95. ^ “gpt-2 (https://github.com/openai/gpt-2)”.\n",
      "GitHub. 2023年3⽉13⽇閲覧。\n",
      "96.  ChatGPT: Optimizing Language Models\n",
      "for Dialogue (https://openai.com/blog/chatg\n",
      "pt/)” (英語). OpenAI (2022年11⽉30⽇). 2023\n",
      "年1⽉13⽇閲覧。\n",
      "97. ^ “GPT Neo (https://github.com/EleutherAI/\n",
      "gpt-neo)” (2023年3⽉15⽇). 2023年4⽉28⽇\n",
      "閲覧。'\n",
      "----\n",
      "page_content='エンコーダのみ: フルエンコーダ、フルデコーダ\n",
      "エンコーダー - デコーダー: フルエンコーダー、⾃⼰回帰デコーダー\n",
      "デコーダのみ: ⾃⼰回帰エンコーダ、⾃⼰回帰デコーダ\n",
      "ここでの「⾃⼰回帰」とは、「マスク化アテンション」節で説明したように、あるトークンからそれに続く\n",
      "すべてのトークンへのアテンションをゼロにするために、アテンションヘッドにマスクが挿⼊されることを\n",
      "意味する。\n",
      "ほとんどの LLM は事前訓練されており、テキストトークンの訓練データセットが与えられると、モデルはデ\n",
      "ータセット内のトークンを予測する。このような事前訓練には⼀般に 2 つの形式がある[34]。\n",
      "⾃⼰回帰モデル（GPT型、次単語予測）\n",
      "「私が⾷べるのが好きなのは」のようなテキスト部分が与えられると、モデルは「アイスクリーム」のよ\n",
      "うな「次のトークン」を予測する。\n",
      "マスク済みモデル（BERT型[35]、⽳埋め）\n",
      "「私は [MASK] クリームを [MASK] したい」 のようなテキスト部分が与えられると、モデルは「アイ\n",
      "スを⾷べる」のような隠されたトークンを予測する。\n",
      "LLM は、次⽂予測（ Next Sentence Prediction 、 NSP ）のように、データ分布の理解をテストする補助タスク\n",
      "を使⽤して訓練することもある[35]。この場合は、⽂の組が提⽰され、モデルはそれらが訓練コーパス内で連\n",
      "続して出現するかどうかを予測しなければならない。\n",
      "通常、 LLM は特定の損失関数、つまりトークンごとの平均負対数尤度（交差エントロピー損失とも呼ばれ\n",
      "る）を最⼩化するように訓練する。たとえば、⾃⼰回帰モデルで「⾷べるのが好き」が与えられ、確率分布\n",
      " を予測する場合、このトークンに対する負対数尤度損失は   と\n",
      "なる。\n",
      "訓練のとき、訓練を安定させるために正則化損失も使⽤される。ただし、正則化損失は通常、テストや評価\n",
      "の際には使⽤されない。また、負対数尤度だけでなく、他にも多くの評価項⽬がある。詳細については以下\n",
      "の節を参照のこと。\n",
      "最初期の LLM は、数⼗億語の規模のコーパスで訓練が⾏われた。\n",
      "OpenAIのGPT（ generative pre-trained transformer ）シリーズの最初のモデルであるGPT-1は、 2018 年に、 9'\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# 類似文書を表示\n",
    "for doc in relavant_docs: \n",
    "    print(doc)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6064a4",
   "metadata": {},
   "source": [
    "##### 4-2. 履歴から質問を作り直す\n",
    "それを解決するための方法が、1つ目のステップになります。  \n",
    "やっていることは、履歴から質問を作り出しています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "963783de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "教師ありファインチューニングとはどういうことでしょうか？\n"
     ]
    }
   ],
   "source": [
    "# sample1\n",
    "messages = [\n",
    "    HumanMessage(content=\"LLMはどんな訓練方法がありますか？\"),\n",
    "    AIMessage(content=\"LLMの訓練方法には、教師ありファインチューニング、強化学習、ツールのファインチューニング、検索拡張生成（RAG）などがあります。\"),\n",
    "]\n",
    "new_msg = contextualize_chain.invoke({\"chat_history\": messages, \"input\": \"一つ目について教えてください\"})\n",
    "print(new_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef2a61ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythonの学習に書籍を使用する方法について教えてください。\n"
     ]
    }
   ],
   "source": [
    "# sample2\n",
    "messages = [\n",
    "    HumanMessage(content=\"Pythonについて教えて\"),\n",
    "    AIMessage(content=\"Pythonは、1991年にオランダ人プログラマーのグイド・ヴァンロッサム氏によって開発されたオープンソース形式のプログラミング言語です。主に人工知能の開発、データ処理、Webアプリケーションの開発など幅広い用途で使用されています。また、初心者にも学びやすい言語とされ、豊富なライブラリが存在するのが特徴です。\"),\n",
    "    HumanMessage(content=\"どんな勉強方法がありますか？\"),\n",
    "    AIMessage(content=\"Pythonを学ぶ方法にはいくつかの選択肢があります。一つは書籍を使用して学習する方法で、これは自分で内容を選びながら学ぶことが推奨されます。また、無料の動画サイトやYouTubeでPythonに関する教育動画を視聴する方法もあります。さらに、Progateやドットインストール、Udemyなどの有料の学習サイトを利用する方法も一般的です。それぞれの方法にはメリットとデメリットがあるため、個々の学習スタイルや目的に合わせて選択することが重要です。\"),\n",
    "]\n",
    "\n",
    "new_msg = contextualize_chain.invoke({\"chat_history\": messages, \"input\": \"一つ目について教えてください\"})\n",
    "print(new_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb82f7",
   "metadata": {},
   "source": [
    "#### 4-3. チャットの実装\n",
    " ここでは公式ドキュメントの方法ではなく、理解のしやすさとバージョン更新の影響を減らすために  \n",
    " Langchainの基本的な（変更が今後すくなさそうな）処理で実装しています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98de9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_sample = [\n",
    "    \"LLMはどんな訓練方法がありますか？\",\n",
    "    \"2つめについて教えてください\"\n",
    "]\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cc82eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human LLMはどんな訓練方法がありますか？ > LLMの訓練方法について教えてください。\n",
      "AI: LLMの訓練方法には、次単語予測を行う自己回帰モデル（GPT型）と、隠されたトークンを予測するマスク済みモデル（BERT型）があります。さらに、次文予測（NSP）などの補助タスクを用いることもあります。訓練時には、特定の損失関数（負対数尤度）を最小化するほか、正則化損失が使用されることもあります。\n",
      "Human 2つめについて教えてください > マスク済みモデルについて教えてください。\n",
      "AI: 2つめのマスク済みモデル（BERT型）では、入力テキストの一部を隠し（マスクし）、その隠された部分を予測するようにモデルを訓練します。これにより、文全体のコンテキストを考慮しながら予測を行う能力を向上させます。この手法は、文の意味理解や文脈把握に優れており、自然言語処理タスクに広く応用されています。\n"
     ]
    }
   ],
   "source": [
    "for msg in messages_sample:\n",
    "    # 質問を修正する\n",
    "    new_msg = contextualize_chain.invoke({\"chat_history\": messages, \"input\": msg})\n",
    "    print(\"Human\", msg, \">\", new_msg)\n",
    "    # 関連ドキュメントを取得\n",
    "    relavant_docs = retriever.invoke(new_msg, k=3)\n",
    "    # 質問に同意する\n",
    "    response = chain.invoke({\"chat_history\": messages, \"context\": relavant_docs, \"input\": msg})\n",
    "    print(\"AI:\", response.content)\n",
    "    # メッセージを保存\n",
    "    messages.extend([\n",
    "        HumanMessage(content=msg), # 作り直したほうではなく、ユーザー入力のほうにする\n",
    "        AIMessage(content=response.content)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7df83c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='LLMはどんな訓練方法がありますか？'),\n",
       " AIMessage(content='LLMの訓練方法には、次単語予測を行う自己回帰モデル（GPT型）と、隠されたトークンを予測するマスク済みモデル（BERT型）があります。さらに、次文予測（NSP）などの補助タスクを用いることもあります。訓練時には、特定の損失関数（負対数尤度）を最小化するほか、正則化損失が使用されることもあります。'),\n",
       " HumanMessage(content='2つめについて教えてください'),\n",
       " AIMessage(content='2つめのマスク済みモデル（BERT型）では、入力テキストの一部を隠し（マスクし）、その隠された部分を予測するようにモデルを訓練します。これにより、文全体のコンテキストを考慮しながら予測を行う能力を向上させます。この手法は、文の意味理解や文脈把握に優れており、自然言語処理タスクに広く応用されています。')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b19c3c",
   "metadata": {},
   "source": [
    "#### 4-5. チャットの実装 Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acf299bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: LLMはどんな訓練方法がありますか？ > LLMの訓練方法について教えてください。\n",
      "|LL|M|の|訓|練|方法|には|、|自己|回|帰|モデル|（|GPT|型|）|で|次|の|ト|ーク|ン|を|予|測|する|方法|や|、|マ|スク|済|み|モデル|（|B|ERT|型|）|で|隠|された|ト|ーク|ン|を|予|測|する|方法|があります|。|さらに|、|次|文|予|測|（|NS|P|）|など|の|補|助|タ|スク|を|用|いた|訓|練|も|可能|です|。|訓|練|時|には|、|負|対|数|尤|度|損|失|を|最|小|化|する|こと|が|一般|的|です|。||Human: 2つめについて教えてください > どういうことですか？\n",
      "|2|つ|め|の|方法|、|マ|スク|済|み|モデル|（|B|ERT|型|）|では|、|テ|キ|スト|中|の|一|部|の|単|語|を|マ|スク|（|隠|す|）|し|、その|マ|スク|された|単|語|を|予|測|する|よう|モデル|を|訓|練|します|。この|手|法|に|より|、|文|全|体|の|文|脈|を|理解|する|能力|が|向|上|します|。|これは|特|に|文|の|意味|理解|や|自然|言|語|処|理|タ|スク|に|効果|的|です|。||/n\n"
     ]
    }
   ],
   "source": [
    "for msg in messages_sample:\n",
    "    # 質問を修正する\n",
    "    new_msg = contextualize_chain.invoke({\"chat_history\": messages, \"input\": msg})\n",
    "    print(\"Human:\", msg, \">\", new_msg)\n",
    "    # 関連ドキュメントを取得\n",
    "    relavant_docs = retriever.invoke(new_msg, k=3)\n",
    "    # 質問に回答する Streaming\n",
    "    full_response = \"\"\n",
    "    for r in chain.stream({\"chat_history\": messages,\"context\": relavant_docs, \"input\": msg}):\n",
    "        print(r.content, end=\"|\")\n",
    "print(\"/n\")\n",
    "messages.extend([\n",
    "    HumanMessage(content=msg),\n",
    "    AIMessage(content=full_response)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718b795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
